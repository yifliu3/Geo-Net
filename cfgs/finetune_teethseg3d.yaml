optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0005, 
  weight_decay : 0.05
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 300,
    initial_epochs : 10
    },
}

bnmscheduler: {
  type: Lambda,
  kwargs: {
    decay_step: 20,
    bn_momentum: 0.1,
    bn_decay: 0.5,
    },
}

dataset : {
  train : { _base_: cfgs/dataset_configs/Teethseg3D_finetune.yaml, 
            others: {subset: 'train', bs: 2, npoints: 16000, whole: False}},
  val : { _base_: cfgs/dataset_configs/Teethseg3D_finetune.yaml, 
            others: {subset: 'test', bs: 1}},
}

model : {
  NAME: PointTransformer_seg,
  m: 0.999,
  T: 0.07,
  K: 16384,
  pos_embed_hidden_dim: 128,

  transformer_config: {
    mask_ratio: 0.75,
    trans_dim: 384,
    depth: 12,
    dec_depth: 1,
    use_sigmoid: true,
    use_moco_loss: false,
    num_heads: 4,
    group_size: 32, 
    num_group: 512, 
    encoder_dims: 256,
    nclasses: 17,
    drop_path_rate: 0.1,
    encoder_dims: 256,
    downsample_targets: [8192, 4096, 2048],
  }
}

total_bs : 2
step_per_update : 1
grad_norm_clip : 10
max_epoch : 300
